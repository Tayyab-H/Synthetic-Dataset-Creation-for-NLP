{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4e501e-452f-4fa6-8722-0686646aff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: flatbuffers\n",
      "Successfully installed flatbuffers-23.5.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.5.0 requires absl-py~=0.10, but you have absl-py 1.1.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires flatbuffers~=1.12.0, but you have flatbuffers 23.5.26 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.9.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "tensorflow 2.9.1 requires flatbuffers<2,>=1.12, but you have flatbuffers 23.5.26 which is incompatible.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: c:\\users\\tayya\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.0\n",
      "  Using cached protobuf-3.20.0-cp310-cp310-win_amd64.whl (903 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "Successfully installed protobuf-3.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in e:\\miniconda\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from pyttsx3) (305)\n",
      "Requirement already satisfied: comtypes in e:\\miniconda\\lib\\site-packages (from pyttsx3) (1.1.14)\n",
      "Requirement already satisfied: pypiwin32 in e:\\miniconda\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pandas in e:\\miniconda\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\miniconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in e:\\miniconda\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\miniconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in e:\\miniconda\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in e:\\miniconda\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.7.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in e:\\miniconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\miniconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in e:\\miniconda\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in e:\\miniconda\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\miniconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tayya\\appdata\\roaming\\python\\python310\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\miniconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\miniconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\miniconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\miniconda\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\miniconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\miniconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\miniconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\miniconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\miniconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\miniconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\miniconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.0\n",
      "    Uninstalling protobuf-3.20.0:\n",
      "      Successfully uninstalled protobuf-3.20.0\n",
      "Successfully installed protobuf-4.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install flatbuffers\n",
    "!pip install protobuf==3.20.0\n",
    "!pip install pyttsx3;\n",
    "!pip install pandas\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f113bb5f-23dc-40ce-adc4-f4b9f97bd72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import pyttsx3;\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a196ac4f-aafe-44f8-b083-ab70e3654b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class that actually executes the commands to retrieve email information\n",
    "class Command():\n",
    "    def __init__(self):\n",
    "        outlook = win32com.client.Dispatch('outlook.application')\n",
    "        self.mapi = outlook.GetNamespace(\"MAPI\")\n",
    "        \n",
    "    def readLastInboxMessage(self):\n",
    "        inbox = self.mapi.GetDefaultFolder(6)\n",
    "        messages = inbox.Items\n",
    "        message = messages.GetLast()\n",
    "        return message.Body\n",
    "    \n",
    "    def readLastInboxSubject(self):\n",
    "        inbox = self.mapi.GetDefaultFolder(6)\n",
    "        messages = inbox.Items\n",
    "        message = messages.GetLast()\n",
    "        return message.Subject\n",
    "\n",
    "    def getAttachmentofLastEmail(self):\n",
    "        inbox = self.mapi.GetDefaultFolder(6)\n",
    "        messages = inbox.Items\n",
    "        message = messages.GetLast()\n",
    "        return message.Attachments  \n",
    "    \n",
    "    def execute(self, commandType):\n",
    "        if commandType == 1:\n",
    "            return self.readLastInboxMessage()\n",
    "        elif commandType == 2:\n",
    "            return self.readLastInboxSubject()\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baabf17c-2679-4882-865f-75ed619ff180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary = True) #Loads in pretrained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490cf292-4155-49a8-9ad3-f2c31ac121ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('files', 0.7133817076683044),\n",
       " ('filing', 0.647048830986023),\n",
       " ('filed', 0.5737501382827759),\n",
       " ('refile', 0.5691325664520264),\n",
       " ('Rod_Aydelotte_photo', 0.5590430498123169),\n",
       " ('File', 0.5576274991035461),\n",
       " ('fi_le', 0.551184892654419),\n",
       " ('Image_###K_GIF', 0.5502156019210815),\n",
       " ('Filing', 0.5267105102539062),\n",
       " ('Image_##K_GIF', 0.5109704732894897)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"file\")#Test to check what most similar words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "784d1367-b848-43da-881a-770b8da3762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 20, 300)\n"
     ]
    }
   ],
   "source": [
    "#Gets and reshapes all the data from the dataset to be in the correct format for the NN\n",
    "colnames = [\"input\",\"label\"]\n",
    "ds = pd.read_csv('synthetic_training_data.csv', usecols = colnames)\n",
    "with open(\"stoplist.txt\", \"r\") as F:\n",
    "    stoplist = F.read()\n",
    "    clean = []\n",
    "for i in range(0, len(ds[\"input\"])):\n",
    "    clean.append([word for word in ds[\"input\"][i].split() if word not in stoplist])\n",
    "\n",
    "x_train = np.array([])\n",
    "zero = np.zeros(shape = (1,300))\n",
    "\n",
    "for i in range(0, len(ds[\"input\"])):\n",
    "    sentence = clean[i]\n",
    "    vec = np.array([])\n",
    "    for j in range(0,len(sentence)):\n",
    "        word = model[sentence[j]]\n",
    "        vec = np.append(vec, word)\n",
    "    vec = vec.reshape(j+1,300)\n",
    "    for k in range(j,19):\n",
    "        vec = np.append(vec, zero)\n",
    "    vec = np.array(vec)\n",
    "    vec = vec.reshape(20,300)\n",
    "    x_train = np.append(x_train, vec)\n",
    "x_train = x_train.reshape(len(ds[\"input\"]),20, 300)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eebd5c21-f45f-4501-8623-696cbf12b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 3)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "temp = ds[\"label\"]\n",
    "y_train = []\n",
    "for i in temp:\n",
    "    current = [0] * num_classes\n",
    "    current[i-1] = 1\n",
    "    y_train.append(current)\n",
    "\n",
    "y_train = np.array(y_train, dtype = int)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74445643-0a79-4efd-9aae-d87860f9f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0938 - accuracy: 0.4348\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0754 - accuracy: 0.6830\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0496 - accuracy: 0.7482\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0103 - accuracy: 0.8348\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.9583 - accuracy: 0.8580\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.8968 - accuracy: 0.8813\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.8235 - accuracy: 0.9045\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.7410 - accuracy: 0.9223\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.6516 - accuracy: 0.9429\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.5621 - accuracy: 0.9527\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.4759 - accuracy: 0.9705\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.3982 - accuracy: 0.9777\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.3304 - accuracy: 0.9839\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.2740 - accuracy: 0.9875\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.2292 - accuracy: 0.9866\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1898 - accuracy: 0.9937\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.1583 - accuracy: 0.9964\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.1335 - accuracy: 0.9964\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1136 - accuracy: 0.9982\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0975 - accuracy: 0.9973\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0834 - accuracy: 0.9982\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0737 - accuracy: 0.9982\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0651 - accuracy: 0.9991\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0576 - accuracy: 0.9991\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0517 - accuracy: 0.9991\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0462 - accuracy: 0.9991\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0418 - accuracy: 0.9991\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0386 - accuracy: 0.9991\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0351 - accuracy: 0.9991\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0325 - accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "#Creating the Neural NEtwork\n",
    "nnmodel = keras.Sequential()\n",
    "nnmodel.add(keras.layers.InputLayer(input_shape = (20, 300)))\n",
    "nnmodel.add(keras.layers.Flatten())\n",
    "nnmodel.add(keras.layers.Dropout(0.1))\n",
    "nnmodel.add(keras.layers.Dense(units = 2000, activation = \"relu\"))\n",
    "nnmodel.add(keras.layers.Dropout(0.1))\n",
    "nnmodel.add(keras.layers.Dense(units = 1600, activation = \"relu\"))\n",
    "nnmodel.add(keras.layers.Dense(units = 100, activation = \"relu\"))\n",
    "nnmodel.add(keras.layers.Dense(units = 100, activation = \"relu\"))\n",
    "nnmodel.add(keras.layers.Dense(units = 20, activation = \"relu\"))\n",
    "nnmodel.add(keras.layers.Dense(units = num_classes, activation = \"softmax\"))\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "\n",
    "nnmodel.compile(optim, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "nnmodel.save_weights('model.h5')\n",
    "history = nnmodel.fit(x_train, y_train, epochs=30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e05b973c-de3c-4dd0-b10b-3985f64b7aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#All Loss-Accuracy Graphs\n",
    "plt.plot(history.history['accuracy'], color = 'b')\n",
    "plt.plot(history.history['loss'], color = 'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy','loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e24a6f89-0787-4597-b3ec-612d553ad08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0044215028174221516, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nnmodel.evaluate(x=x_valid, y=y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c545b523-a950-4a05-98e7-8754d3c18a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 20, 300)\n"
     ]
    }
   ],
   "source": [
    "#Gets the test set into the correct format\n",
    "colnames = [\"input\",\"label\"]\n",
    "ds = pd.read_csv('synthetic_testing_data.csv', usecols = colnames)\n",
    "#ds = pd.read_csv('synthetic_testing_data.csv', usecols = colnames)\n",
    "with open(\"stoplist.txt\", \"r\") as F:\n",
    "    stoplist = F.read()\n",
    "    clean = []\n",
    "for i in range(0, len(ds[\"input\"])):\n",
    "    clean.append([word for word in ds[\"input\"][i].split() if word not in stoplist])\n",
    "\n",
    "x_test = np.array([])\n",
    "zero = np.zeros(shape = (1,300))\n",
    "\n",
    "for i in range(0, len(ds[\"input\"])):\n",
    "    sentence = clean[i]\n",
    "    vec = np.array([])\n",
    "    for j in range(0,len(sentence)):\n",
    "        word = model[sentence[j]]\n",
    "        vec = np.append(vec, word)\n",
    "    vec = vec.reshape(j+1,300)\n",
    "    for k in range(j,19):\n",
    "        vec = np.append(vec, zero)\n",
    "    vec = np.array(vec)\n",
    "    vec = vec.reshape(20,300)\n",
    "    x_test = np.append(x_test, vec)\n",
    "x_test = x_test.reshape(len(ds[\"input\"]),20, 300)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d064a3b-722f-4793-8e5b-bfa9f76c5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 3)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "temp = ds[\"label\"]\n",
    "y_test = []\n",
    "for i in temp:\n",
    "    current = [0] * num_classes\n",
    "    current[i-1] = 1\n",
    "    y_test.append(current)\n",
    "\n",
    "y_test = np.array(y_test, dtype = int)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bef18af-2f68-4a99-825e-07114313bc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 8ms/step - loss: 0.9598 - accuracy: 0.6781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9598449468612671, 0.6781250238418579]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluates the model against the test set \n",
    "nnmodel.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "833eba41-99c2-4ddf-ae9a-a2cdd88b0e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.4487 - accuracy: 0.8268\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0552 - accuracy: 0.9857\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.0147 - accuracy: 0.9964\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0103 - accuracy: 0.9973\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0205 - accuracy: 0.9946\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0190 - accuracy: 0.9929\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0078 - accuracy: 0.9982\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0056 - accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 3.5986 - accuracy: 0.6388\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.9769 - accuracy: 0.7777\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.4295 - accuracy: 0.9563\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0746 - accuracy: 0.9955\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0200 - accuracy: 0.9973\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0112 - accuracy: 0.9991\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0096 - accuracy: 0.9991\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.0090 - accuracy: 0.9982\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0098 - accuracy: 0.9991\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0072 - accuracy: 0.9991\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0064 - accuracy: 0.9991\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0057 - accuracy: 0.9991\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.0065 - accuracy: 0.9991\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0046 - accuracy: 0.9991\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0036 - accuracy: 0.9982\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.9989 - accuracy: 0.6525\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0940 - accuracy: 0.4107\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.0770 - accuracy: 0.6973\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0524 - accuracy: 0.7625\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 1.0173 - accuracy: 0.8438\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.9690 - accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.9051 - accuracy: 0.8938\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.8316 - accuracy: 0.9143\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.7495 - accuracy: 0.9214\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.6596 - accuracy: 0.9366\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.5594 - accuracy: 0.9571\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.4428 - accuracy: 0.9777\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.3393 - accuracy: 0.9893\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.2570 - accuracy: 0.9920\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.2027 - accuracy: 0.9937\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1618 - accuracy: 0.9973\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1315 - accuracy: 0.9973\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1099 - accuracy: 0.9964\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.0918 - accuracy: 0.9973\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.0775 - accuracy: 0.9964\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0677 - accuracy: 0.9991\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 1.0525 - accuracy: 0.6700\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 1.0999 - accuracy: 0.3071\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0982 - accuracy: 0.3179\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0970 - accuracy: 0.3295\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0946 - accuracy: 0.3902\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0931 - accuracy: 0.4152\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0920 - accuracy: 0.4527\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0900 - accuracy: 0.4973\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0881 - accuracy: 0.5304\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0863 - accuracy: 0.5652\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0843 - accuracy: 0.5777\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0821 - accuracy: 0.6179\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0792 - accuracy: 0.6473\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0772 - accuracy: 0.6696\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0747 - accuracy: 0.6857\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0717 - accuracy: 0.7125\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0689 - accuracy: 0.7143\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0660 - accuracy: 0.7509\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0625 - accuracy: 0.7554\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0593 - accuracy: 0.7768\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0560 - accuracy: 0.7830\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.0802 - accuracy: 0.4619\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1010 - accuracy: 0.2732\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1005 - accuracy: 0.2929\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1009 - accuracy: 0.2714\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1002 - accuracy: 0.2839\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1001 - accuracy: 0.2777\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.1000 - accuracy: 0.2884\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.0997 - accuracy: 0.2866\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0998 - accuracy: 0.2848\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0995 - accuracy: 0.2991\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0993 - accuracy: 0.3125\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0990 - accuracy: 0.3143\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0994 - accuracy: 0.3018\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0986 - accuracy: 0.3196\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0986 - accuracy: 0.3089\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0982 - accuracy: 0.3286\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0982 - accuracy: 0.3045\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.0982 - accuracy: 0.3205\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.0977 - accuracy: 0.3250\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.0980 - accuracy: 0.3187\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.0973 - accuracy: 0.3295\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.0993 - accuracy: 0.2775\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1011 - accuracy: 0.2812\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1011 - accuracy: 0.2830\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1014 - accuracy: 0.2705\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1012 - accuracy: 0.2795\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.1008 - accuracy: 0.2768\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 1.1008 - accuracy: 0.2795\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.1014 - accuracy: 0.2679\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.1013 - accuracy: 0.2723\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.1011 - accuracy: 0.2893\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 1.1011 - accuracy: 0.2804\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 1.1006 - accuracy: 0.2920\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.1007 - accuracy: 0.2973\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1009 - accuracy: 0.2875\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1011 - accuracy: 0.2839\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 1.1011 - accuracy: 0.2786\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1008 - accuracy: 0.2741\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1008 - accuracy: 0.2893\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1006 - accuracy: 0.2848\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1006 - accuracy: 0.2839\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1009 - accuracy: 0.2750\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.0998 - accuracy: 0.2669\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1011 - accuracy: 0.2893\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1014 - accuracy: 0.2830\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1011 - accuracy: 0.2732\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.1011 - accuracy: 0.2705\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 1.1015 - accuracy: 0.2812\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1015 - accuracy: 0.2759\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1010 - accuracy: 0.2696\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1012 - accuracy: 0.2786\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1008 - accuracy: 0.2768\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1008 - accuracy: 0.2750\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1008 - accuracy: 0.2750\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1013 - accuracy: 0.2902\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1010 - accuracy: 0.2759\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1010 - accuracy: 0.2705\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1009 - accuracy: 0.2920\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1013 - accuracy: 0.2696\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1011 - accuracy: 0.2839\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 1.1009 - accuracy: 0.2679\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 1.1009 - accuracy: 0.2786\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 1.1009 - accuracy: 0.2893\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 1.0998 - accuracy: 0.2663\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ignore this - used for generated results and graphs\n",
    "for i in range(3,10):\n",
    "    nnmodel.load_weights('model.h5')\n",
    "    lr = 1 * pow(10,-i)\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    nnmodel.compile(optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = nnmodel.fit(x_train, y_train, epochs=20, batch_size = 64)\n",
    "    plt.plot(lr, float(nnmodel.evaluate(x=x_test, y=y_test)[1]), 'bo')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c14cf0dc-27ba-4462-9099-b939b8df3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 :  1\n",
      "3 :  1\n",
      "4 :  1\n",
      "5 :  1\n",
      "6 :  1\n",
      "7 :  1\n",
      "8 :  1\n",
      "9 :  1\n",
      "10 :  1\n",
      "11 :  1\n",
      "12 :  1\n",
      "13 :  1\n",
      "14 :  1\n",
      "15 :  1\n",
      "16 :  1\n",
      "17 :  1\n",
      "18 :  2\n",
      "19 :  2\n",
      "20 :  1\n",
      "21 :  1\n",
      "22 :  2\n",
      "23 :  3\n",
      "24 :  3\n",
      "25 :  2\n",
      "26 :  3\n",
      "27 :  2\n",
      "28 :  2\n",
      "29 :  2\n",
      "30 :  2\n",
      "31 :  2\n",
      "32 :  3\n",
      "33 :  3\n",
      "34 :  2\n",
      "35 :  1\n",
      "36 :  1\n",
      "37 :  3\n",
      "38 :  3\n",
      "39 :  3\n",
      "40 :  2\n",
      "41 :  2\n",
      "42 :  3\n",
      "43 :  3\n",
      "44 :  1\n",
      "45 :  3\n",
      "46 :  1\n"
     ]
    }
   ],
   "source": [
    "#an in depth look at the model's class predictions in the testing set\n",
    "ar = nnmodel.predict(x=x_test)\n",
    "excelnumber = 2\n",
    "for i in ar:\n",
    "    print(excelnumber, \": \",i.tolist().index(max(i)) + 1)\n",
    "    excelnumber +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8f852543-5cd9-442e-9f1b-a658316dc7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['return', 'topic']\n",
      "[[0.9146363  0.08253296 0.00283068]]\n",
      "Class Number:  1\n",
      "Email Output: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=340RO1NFOP1LW&T=O&U=https%3A%2F%2Fimages-eu.ssl-images-amazon.com%2Fimages%2FG%2F01%2Fnav%2Ftransp.gif&H=U4QVULOGULK3AB5YEICIRZGOQGEA&ref_=pe_27063361_487055811_opens> \\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=2EZIWFJLF2IF4&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fref%3Dpe_27063361_487055811_TE_g_i&H=DZDLP9956CATGLSA9VJP6YAAFDKA&ref_=pe_27063361_487055811_TE_g_i> \\t Your Orders <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=1KMD1S1SLE9AY&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fcss%2Fyour-orders-access%2Fref%3Dpe_27063361_487055811_TE_oh_tn&H=2G4AUARB2VHP4ZHPTCA67MT76FMA&ref_=pe_27063361_487055811_TE_oh_tn>  \\t  |   \\tYour Account <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3R502S5ARJPJ4&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fcss%2Fyour-account-access%2Fref%3Dpe_27063361_487055811_TE_ya_tn&H=IOJHPFFASSCOYCOBSDHQANOPB1OA&ref_=pe_27063361_487055811_TE_ya_tn>  \\t  |   \\tAmazon.co.uk <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=17YA9FGHHZNED&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fref%3Dpe_27063361_487055811_TE_g_tn&H=CL6N0AJDMDM8EF8YQZFE2IHD0OOA&ref_=pe_27063361_487055811_TE_g_tn>  \\t\\r\\n\\r\\nDispatch Confirmation\\r\\n\\r\\nOrder: #203-5325341-1706714 <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=1DNNJSM47WHWA&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fcss%2Fsummary%2Fedit.html%2Fref%3Dpe_27063361_487055811_TE_od_tn%3Fie%3DUTF8%26orderID%3D203-5325341-1706714&H=ZUAUAXQV9NSBFXJKVGVWO81SIZGA&ref_=pe_27063361_487055811_TE_od_tn>  \\r\\nHello, \\r\\n\\r\\nWe thought you\\'d like to know that we\\'ve dispatched your item(s). Your order is on the way, and can no longer be changed. If you need to return an item or manage other orders, please visit Your Orders <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3PVTFJ2TOWEWB&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fcss%2Fyour-orders-access%2Fref%3Dpe_27063361_487055811_TE_oh_bd&H=KTHYOU43CJ0H6FM8EIUTTYCAZDWA&ref_=pe_27063361_487055811_TE_oh_bd>  on Amazon.co.uk \\r\\n\\r\\nArriving:\\r\\nTuesday, September 14 \\r\\n\\r\\nTrack your package <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=QSUJCZGFHPLZ&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fcss%2Fshiptrack%2Fview.html%2Fref%3Dpe_27063361_487055811_TE_typ%3Fie%3DUTF8%26addressID%3Dnmjjrvmummkq%26latestArrivalDate%3D1631646000%26orderID%3D203-5325341-1706714%26shipmentDate%3D1631455909%26orderingShipmentId%3D33099201466302%26packageId%3D1&H=AASLO78FSXBUQIUOD7JMUC5ZW9AA&ref_=pe_27063361_487055811_TE_typ>  \\t\\r\\nYour order was sent to:\\r\\n\\r\\n\\r\\nTayyab\\r\\nSolihull \\r\\n\\r\\nOrder Total: \\t£6.53 \\t\\r\\nPaid by Visa: \\t£6.53 \\t\\r\\n<https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=2OALNDGU79RDC&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2F%3Fref%3Dsce_wms%26ref_%3Dpe_27063361_487055811&H=6KSYSVOOUTL9QC7KBYNNMREHOGMA&ref_=pe_27063361_487055811> \\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=276YCFFF9BEHT&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2F%3Fref%3Dsce_wms%26ref_%3Dpe_27063361_487055811&H=UTGCYUQBRTLBOZUOAQAAGHBB7MKA&ref_=pe_27063361_487055811> \\tJust ask: \"Alexa, where\\'s my stuff?\" <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=2HWXJ82IUWZ0O&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2F%3Fref%3Dsce_wms%26ref_%3Dpe_27063361_487055811&H=3SWXNLDRQYW355KQLRDXICDIR4KA&ref_=pe_27063361_487055811> \\t\\r\\nYour item(s) is (are) being sent by Amazon Logistics. Your tracking number is QB0145838179. Depending on the delivery method you chose, it\\'s possible that the tracking information might not be visible immediately. Learn more about Tracking <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3T8EF1ALZZA9&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Ftracking%3Fref%3DTE_tra%26ref_%3Dpe_27063361_487055811&H=6BL6BHEQNA6LP1MPDNE0DIJOXOKA&ref_=pe_27063361_487055811> . \\r\\n\\r\\nIf you have a mobile device, you can use the free Amazon Mobile App <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3PAJ6ODR3BF0O&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fb%2Fref%3Dpe_27063361_487055811_help_dt_moboapp%3Fnode%3D4816518031&H=ESYNLDGU0A8NUIFL8WKGINXBDKWA&ref_=pe_27063361_487055811_help_dt_moboapp>  to receive delivery notifications and track your parcel on the go. \\r\\n\\r\\nOrder summary \\r\\n\\t\\r\\n\\t\\r\\n<https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=20K4LGPS22JA&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fdp%2FB08VJ1J5DS%2Fref%3Dpe_27063361_487055811_TE_dp_i1&H=NYKZQPTOZ6YFZRO0GNN6EYED9I4A&ref_=pe_27063361_487055811_TE_dp_i1>  <https://m.media-amazon.com/images/I/51afF5e1cmS._SY115_SX115_.jpg> \\t\\r\\n*\\tIndeme A5 Notebook/Notepad - Lined A5 Notebook Journal with Premium Paper, 5.8\" X 8.4\", Hardcover, 144 Pages, Back Pocket, Bookmark, College Ruled Jou <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=OHTQ6OCRN7J5&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fdp%2FB08VJ1J5DS%2Fref%3Dpe_27063361_487055811_TE_dp_1&H=QHPJJAMK97KPXZSA3RGGLRKJY4OA&ref_=pe_27063361_487055811_TE_dp_1> \\r\\n\\tSold by indeme \\r\\n\\r\\n£6.53 \\t\\r\\n\\t\\r\\n\\t\\r\\nIt\\'s easy to return an item. Visit our Online Returns Centre <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=T91ELZW7QM4L&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Freturns-support%3Fref%3DTE_r%26ref_%3Dpe_27063361_487055811&H=ZB5RPWAZOIWREBEZXKNL5TXOWDOA&ref_=pe_27063361_487055811> . \\r\\nLearn how to recycle your packaging at Amazon Second Chance <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=2BVJQTIC1YXB0&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Famsc%3Fref_%3Dpe_27063361_487055811_ascyorn&H=LUU8R6HJMCAMWAKQWZCSCVEV8OGA&ref_=pe_27063361_487055811_ascyorn> . \\r\\nIf you need further assistance with your order, please visit Customer Service <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3NQG0BS7UTIG8&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fcustomerservice%3Fref%3DTE_cs%26ref_%3Dpe_27063361_487055811&H=6GXA6CUCHPDXBS6T2Q2RNAVCCCSA&ref_=pe_27063361_487055811> . \\r\\n\\r\\n\\r\\nWe hope to see you again soon.\\r\\nAmazon.co.uk \\r\\n\\r\\nBuy it again \\t\\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=1LQBOXJI3VCTL&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB01A5NNO7W%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_im%3F_encoding%3DUTF8%26pd_rd_i%3DB01A5NNO7W%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=GYBJPKOH5AFWTVPGBQDDKQHEO9EA&ref_=pe_27063361_487055811_pd_te_s_rp_im> \\t\\r\\nMaybelline Brow Drama Crayon 4 Dark Brown <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=30VVVG5KQ2KU3&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB01A5NNO7W%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_ti%3F_encoding%3DUTF8%26pd_rd_i%3DB01A5NNO7W%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=LKPT3S7TH7U6PXOMMC1OFNWLQ7CA&ref_=pe_27063361_487055811_pd_te_s_rp_ti>  \\t\\r\\n£2.99 \\t\\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3QKL95KAWI8BC&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB000JEWHWQ%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_im%3F_encoding%3DUTF8%26pd_rd_i%3DB000JEWHWQ%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=YOBM3VNIAX2JVFD56C2AJTA9UBOA&ref_=pe_27063361_487055811_pd_te_s_rp_im> \\t\\r\\nNina Ricci Nina Eau de Toilette - 50 ml <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=20DV2FMTJVFI&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB000JEWHWQ%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_ti%3F_encoding%3DUTF8%26pd_rd_i%3DB000JEWHWQ%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=M2MMLHQL3CADLDG9ITFNDYBHQQGA&ref_=pe_27063361_487055811_pd_te_s_rp_ti>  \\t\\r\\n£31.94 \\t\\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=25OZQ7W62L30Q&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB006VT8G1O%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_im%3F_encoding%3DUTF8%26pd_rd_i%3DB006VT8G1O%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=L9XEDXTWAX9IHMTJQOW5B8TDQ2EA&ref_=pe_27063361_487055811_pd_te_s_rp_im> \\t\\r\\nThis Works Deep Sleep Pillow Spray, 75 ml <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=1X1FAPH927Y4R&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fproduct%2FB006VT8G1O%2Fref%3Dpe_27063361_487055811_pd_te_s_rp_ti%3F_encoding%3DUTF8%26pd_rd_i%3DB006VT8G1O%26pd_rd_r%3DEC0QGMRZEK33Y7SZD6EZ%26pd_rd_w%3D746WQ%26pd_rd_wg%3DKgGmX%26pf_rd_p%3D35d9b767-2041-4211-baa2-9b602a82f05d&H=4OI7CXAKAQ1CNMAQXCLUXVS3RYMA&ref_=pe_27063361_487055811_pd_te_s_rp_ti>  \\t\\r\\n£16.58 \\t\\r\\n\\r\\nYou can cancel this order within 14 days, beginning from the day you receive the product (subject to certain exceptions <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=2KEYNE4T0IUZI&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fhelp%2Fcustomer%2Fdisplay.html%2Fref%3Dpe_27063361_487055811_TE_aes%3Fie%3DUTF8%26nodeId%3D1040616&H=HWNTB8EE8EFMBRZPD7YRIAR4AEIA&ref_=pe_27063361_487055811_TE_aes> ). We will reimburse all payments received from you for the goods purchased and will also reimburse outbound delivery charges (for the least expensive type of delivery offered by us). You will be responsible for the cost of returning the product to us unless we delivered it to you in error, it is faulty, or you purchased shoes, clothing and accessories (check our Returns Policy <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=343QI5SGE3HV2&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fhelp%2Fcustomer%2Fdisplay.html%2Fref%3Dpe_27063361_487055811_TE_aes%3Fie%3DUTF8%26nodeId%3D1161002&H=PVHPWXFVIXIHWO0Z46NA0KU0UOKA&ref_=pe_27063361_487055811_TE_aes> ). You may be subject to increased return costs if the product can’t be returned normally by post. \\r\\n\\r\\nYou can request a cancellation by visiting our Returns Support Centre <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3FYXS5KZ3HOH0&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Freturns-support%3Fref%3DTE_r%26ref_%3Dpe_27063361_487055811&H=AFZ4FC4MQAG7KEQQYHI9B7NE7MEA&ref_=pe_27063361_487055811> ; by contacting us <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=3GSNF4CJUUUVD&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fhelp%2Fcustomer%2Fdisplay.html%2Fref%3Dpe_27063361_487055811_TE_aes%3Fie%3DUTF8%26nodeId%3D502564&H=XTIHAPG8IZ0ATV3K1TFLDRPJXC8A&ref_=pe_27063361_487055811_TE_aes> ; or completing this form <https://www.amazon.co.uk/gp/f.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=21S9H5DDVPDAR&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fcancellationform%3Fref_%3Dpe_27063361_487055811&H=EMDLAJXJZMEKHITIAHOPYYPJPPOA&ref_=pe_27063361_487055811>  and sending it by post.\\r\\n\\r\\nPlease also see our Returns Policy <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=NZDMI2UPIB4Q&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fhelp%2Fcustomer%2Fdisplay.html%2Fref%3Dpe_27063361_487055811_TE_aes%3Fie%3DUTF8%26nodeId%3D1161002&H=3AU4FSV60BX7AORZWUF0ZBIXAKCA&ref_=pe_27063361_487055811_TE_aes>  to learn more about our 30 day returns guarantee which outlines that you can return items for a full refund of the item price within 30 days.\\r\\n\\r\\nAmazon EU, Société à responsabilité limitée, 38 avenue John F. Kennedy, L-1855 Luxembourg. Share capital: EUR 125.000; Registered in Luxembourg; RCS Luxembourg No: B 101818; Business Licence Number: 134248; Luxembourg VAT Registration Number: LU 20260743.\\r\\n\\r\\nLearn more about your statutory rights here <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=ZQ3SJ7MH70D1&T=C&U=https%3A%2F%2Fwww.amazon.co.uk%2Fgp%2Fhelp%2Fcustomer%2Fdisplay.html%2Fref%3Dpe_27063361_487055811_TE_que_ysr%3FnodeId%3D1161020&H=IVBOJUPBLKG3I1LIYPWIGCSQGSEA&ref_=pe_27063361_487055811_TE_que_ysr> .\\r\\n\\r\\nPlease note: This email was sent from a notification-only address that can\\'t accept incoming email. Please do not reply to this message.\\r\\n\\r\\n <https://www.amazon.co.uk/gp/r.html?C=2X8R0PK3LTH9J&K=2VP7D0BP8A0BL&M=urn:rtn:msg:202109121417186c0d06d28b354a68ad32e78e0050p0eu&R=1Z14HPQMRLCX9&T=E&U=https%3A%2F%2Fimages-eu.ssl-images-amazon.com%2Fimages%2FG%2F01%2Fnav%2Ftransp.gif&H=JXDGAL2MV7TATKGYFUO96AMXHXMA&ref_=pe_27063361_487055811_open> '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Executes the email command using any given sentence. YOU MUST USE REAL WORDS\n",
    "sentence = \"return the topic\"\n",
    "clean = []\n",
    "clean = [word for word in sentence.split() if word not in stoplist]\n",
    "print(clean)\n",
    "vec = np.array([])\n",
    "for j in range(0,len(clean)):\n",
    "    word = model[clean[j]]\n",
    "    vec = np.append(vec, word)\n",
    "vec = vec.reshape(j+1,300)\n",
    "for k in range(j,19):\n",
    "    vec = np.append(vec, zero)\n",
    "vec = np.array(vec)\n",
    "vec = vec.reshape(1, 20, 300)\n",
    "\n",
    "ar = np.array(nnmodel.predict(vec))\n",
    "print(ar)\n",
    "classnum =  np.argmax(ar) + 1\n",
    "print(\"Class Number: \" , classnum)\n",
    "\n",
    "emailController = Command()\n",
    "print(\"Email Output: \")\n",
    "emailController.execute(classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e8048-3ef3-49d5-97e9-7fdae92580a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e8cee-f90d-4521-acae-4ca94db22943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
