{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b82038-3bee-4c9f-93aa-bdd8204def8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8c54d9-2eb6-4a23-bac3-061560730a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05e3a01-b372-45cb-aa21-81b128aa66ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colnames = [\"input\",\"label\"]\n",
    "ds = pd.read_csv('training_data.csv', usecols = colnames)\n",
    "with open(\"stoplist.txt\", \"r\") as F:\n",
    "    stoplist = F.read()\n",
    "    clean = []\n",
    "for i in range(0, len(ds[\"input\"])):\n",
    "    clean.append([word for word in ds[\"input\"][i].split() if word not in stoplist])\n",
    "\n",
    "dataset = []\n",
    "temp = []\n",
    "label = []\n",
    "for i in clean:\n",
    "    for j in i:\n",
    "        for k in range(0,10):\n",
    "            word = model.most_similar(j)[k][0]\n",
    "            temp = i.copy()\n",
    "            temp[i.index(j)] = word\n",
    "            dataset.append(temp)\n",
    "            label.append(ds['label'][clean.index(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd496945-412d-4b9e-b9db-b6509209e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3d68b-c0af-4ea7-ae33-10b158c84e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9a9f1e-d133-417d-a291-38bed67950c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\n",
    "sentences = []\n",
    "for i in dataset:\n",
    "    for j in i:\n",
    "        if i.index(j) == 0:\n",
    "            sentence = sentence + j\n",
    "        else:\n",
    "            sentence = sentence + \" \" + j\n",
    "    sentences.append(sentence)\n",
    "    sentence = \"\"\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'input': sentences,\n",
    "    'label': label\n",
    "})\n",
    "df.to_csv('synthetic_training_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0ce20-99aa-4381-8032-d070a51da39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381f164-3baf-4dd2-8acc-fe909cfae00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
